---
---

@string{aps = {American Physical Society,}}

@inproceedings{lakhotia2019identifying,
  abbr={ICMLA 2019},
  title={Identifying Missing Component in the Bechdel Test Using Principal Component Analysis Method},
  author={Lakhotia, Raghav and Nagesh, Chandra Kanth and Madgula, Krishna},
  booktitle={Proc. of International Conference on Machine Learning and Applications (ICMLA)},
  html = {https://doi.org/10.48550/arXiv.1907.03702},
  bibtex_show={true},
  year={2019},
  preview={bechdel.png},
  abstract={
    A lot has been said and discussed regarding the rationale and significance of the Bechdel Score. It became a digital sensation in 2013 when Swedish cinemas began to showcase the Bechdel test score of a film alongside its rating. The test has drawn criticism from experts and the film fraternity regarding its use to rate the female presence in a movie. The pundits believe that the score is too simplified and the underlying criteria of a film to pass the test must include 1) at least two women, 2) who have at least one dialogue, 3) about something other than a man, is egregious. In this research, we have considered a few more parameters which highlight how we represent females in film, like the number of female dialogues in a movie, dialogue genre, and part of speech tags in the dialogue. The parameters were missing in the existing criteria to calculate the Bechdel score. The research aims to analyze 342 movies scripts to test a hypothesis if these extra parameters, above with the current Bechdel criteria, are significant in calculating the female representation score. The result of the Principal Component Analysis method concludes that the female dialogue content is a key component and should be considered while measuring the representation of women in a work of fiction.
  }
}

@inproceedings{nagesh2019secure,
  abbr={CSITSS 2017},
  title={Secure Handshake Mechanism for Autonomous Flying Agents Using Robust Cryptosystem},
  booktitle={Proc. of 2nd International Conference on Computational Systems and Information Technology for Sustainable Solution (CSITSS)}, 
  author={Nagesh, Chandra Kanth and Rao, KN and Koundinya, Anjan K},
  journal={Proc. of International Conference on Computational Systems and Information Technology for Sustainable Solution (CSITSS)},
  html = {https://doi.org/10.48550/arXiv.1906.08139},
  bibtex_show={true},
  year={2017},
  preview={crypto.png},
  abstract={
    The autonomous flying agents in a Network-centric environment and brings out various security threats and various techniques of Cryptography. Primary Focus is on study and implementation of how cryptographic algorithms can be effectively be used in a warfare scenario. The data security is the utmost key factor for the protection of data in such environments. The paper proposes mechanisms secured data transmission from the command center (which can be the sending flying agent) to shooter target. The command center and shooter target have a unique set of encryption and decryption key which are created randomly by calibrating the security level at run time. In the beginning, the encryption key used for encrypting data is received from a shooter target when the communication is authenticated through UDP sockets. The encrypted data is sent to the shooter target with the signed signature and command center's encryption key. The encrypted data and signature are then decrypted and verified respectively at the shooter target. The time analysis is performed and observed inputs are provided to the command center.
  }
}

@misc{nagesh2022birds,
      title={The Birds Need Attention Too: Analysing usage of Self Attention in identifying bird calls in soundscapes}, 
      author={Chandra Kanth Nagesh and Abhishek Purushothama},
      year={2022},
      eprint={2211.07722},
      html = {https://arxiv.org/abs/2211.07722},
      bibtex_show={true},
      archivePrefix={arXiv},
      primaryClass={cs.MM},
      preview={Bird-Arch.png},
      abstract={
        Birds are vital parts of ecosystems across the world and are an excellent measure of the quality of life on earth. Many bird species are endangered while others are already extinct. Ecological efforts in understanding and monitoring bird populations are important to conserve their habitat and species, but this mostly relies on manual methods in rough terrains. Recent advances in Machine Learning and Deep Learning have made automatic bird recognition in diverse environments possible. Birdcall recognition till now has been performed using convolutional neural networks. In this work, we try and understand how self-attention can aid in this endeavor. With that we build an pre-trained Attention-based Spectrogram Transformer baseline for BirdCLEF 2022 and compare the results against the pre-trained Convolution-based baseline. Our results show that the transformer models outperformed the convolutional model and we further validate our results by building baselines and analyzing the results for the previous year BirdCLEF 2021 challenge. Source code available at this https://github.com/ck090/BirdCLEF-22
      }
}

@misc{nagesh2023salient,
      title={Salient Object Detection for Images Taken by People With Vision Impairments}, 
      author={Chandra Kanth Nagesh and Jarek Reynolds and Danna Gurari},
      year={2023},
      eprint={2301.05323},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      html = {https://arxiv.org/abs/2301.05323},
      bibtex_show={true},
      preview={salient.png},
      abstract={
        Salient object detection is the task of producing a binary mask for an image that deciphers which pixels belong to the foreground object versus background. We introduce a new salient object detection dataset using images taken by people who are visually impaired who were seeking to better understand their surroundings, which we call VizWiz-SalientObject. Compared to seven existing datasets, VizWiz-SalientObject is the largest (i.e., 32,000 human-annotated images) and contains unique characteristics including a higher prevalence of text in the salient objects (i.e., in 68% of images) and salient objects that occupy a larger ratio of the images (i.e., on average, ~50% coverage). We benchmarked seven modern salient object detection methods on our dataset and found they struggle most with images featuring salient objects that are large, have less complex boundaries, and lack text as well as for lower quality images. We invite the broader community to work on our new dataset challenge by publicly sharing the dataset at this https https://vizwiz.org/tasks-and-datasets/salient-object.
      }
}